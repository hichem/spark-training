{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"iris num.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display 2 elements to make sure data is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5.1,3.5,1.4,0.2,0', u'4.9,3,1.4,0.2,0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = data.map(lambda line : array([float(x) for x in line.split(\",\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5.1, 3.5, 1.4, 0.2, 0. ]), array([4.9, 3. , 1.4, 0.2, 0. ])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for spark mllib algorithms. Those algorithms require the data to be labeled input / output by encapsulating it in LabeledPoint objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(l):\n",
    "    return LabeledPoint(l[4], l[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = pdata.map(lambda l: parse(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [5.1,3.5,1.4,0.2]), LabeledPoint(0.0, [4.9,3.0,1.4,0.2])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdata.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = fdata.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the decision tree classifier to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree.trainClassifier(trainingData, numClasses=3, categoricalFeaturesInfo={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testData.map(lambda row: row.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Confusion Matrix to evaluate the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a matrix containing the test labels as a first column (real values) and predicted values as second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsAndLabels = testData.map(lambda labeledpoint: labeledpoint.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 2.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 1.0),\n",
       " (1.0, 2.0),\n",
       " (1.0, 1.0),\n",
       " (2.0, 2.0),\n",
       " (2.0, 2.0),\n",
       " (2.0, 2.0),\n",
       " (2.0, 2.0),\n",
       " (2.0, 2.0),\n",
       " (2.0, 2.0),\n",
       " (2.0, 2.0),\n",
       " (2.0, 2.0)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsAndLabels.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(predictionsAndLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935483870968\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix = metrics.confusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.,  0.,  0.],\n",
       "       [ 0.,  8.,  0.],\n",
       "       [ 0.,  2.,  8.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix.toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Model Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall for Class #1', 1.0)\n",
      "('Recall for Class #2', 1.0)\n",
      "('Recall for Class #3', 0.8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall for Class #1\", metrics.recall(0))\n",
    "print(\"Recall for Class #2\", metrics.recall(1))\n",
    "print(\"Recall for Class #3\", metrics.recall(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Precision for Class #1', 1.0)\n",
      "('Precision for Class #2', 0.8)\n",
      "('Precision for Class #3', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision for Class #1\", metrics.precision(0))\n",
    "print(\"Precision for Class #2\", metrics.precision(1))\n",
    "print(\"Precision for Class #3\", metrics.precision(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354838709677419"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354838709677419"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354838709677419"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.fMeasure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(\"Iris1.csv\", format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Spark sqlContext to load the data as a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = sqlContext.read.format(\"csv\").options(header='true', inferSchema='true').load('Iris1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print row count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 150\n"
     ]
    }
   ],
   "source": [
    "print('Row count: %s' % df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the data based on a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+---------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|  species|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "|         7.6|        3.0|         6.6|        2.1|virginica|\n",
      "|         7.3|        2.9|         6.3|        1.8|virginica|\n",
      "|         7.2|        3.6|         6.1|        2.5|virginica|\n",
      "|         7.7|        3.8|         6.7|        2.2|virginica|\n",
      "|         7.7|        2.6|         6.9|        2.3|virginica|\n",
      "|         7.7|        2.8|         6.7|        2.0|virginica|\n",
      "|         7.4|        2.8|         6.1|        1.9|virginica|\n",
      "|         7.9|        3.8|         6.4|        2.0|virginica|\n",
      "|         7.7|        3.0|         6.1|        2.3|virginica|\n",
      "+------------+-----------+------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['petal_length'] > 6).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|   species|count|\n",
      "+----------+-----+\n",
      "| virginica|   50|\n",
      "|versicolor|   50|\n",
      "|    setosa|   50|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df['species']).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sepal_length=5.1, sepal_width=3.5, petal_length=1.4, petal_width=0.2, species=u'setosa'),\n",
       " Row(sepal_length=4.9, sepal_width=3.0, petal_length=1.4, petal_width=0.2, species=u'setosa'),\n",
       " Row(sepal_length=4.7, sepal_width=3.2, petal_length=1.3, petal_width=0.2, species=u'setosa'),\n",
       " Row(sepal_length=4.6, sepal_width=3.1, petal_length=1.5, petal_width=0.2, species=u'setosa'),\n",
       " Row(sepal_length=5.0, sepal_width=3.6, petal_length=1.4, petal_width=0.2, species=u'setosa'),\n",
       " Row(sepal_length=5.4, sepal_width=3.9, petal_length=1.7, petal_width=0.4, species=u'setosa'),\n",
       " Row(sepal_length=4.6, sepal_width=3.4, petal_length=1.4, petal_width=0.3, species=u'setosa'),\n",
       " Row(sepal_length=5.0, sepal_width=3.4, petal_length=1.5, petal_width=0.2, species=u'setosa'),\n",
       " Row(sepal_length=4.4, sepal_width=2.9, petal_length=1.4, petal_width=0.2, species=u'setosa'),\n",
       " Row(sepal_length=4.9, sepal_width=3.1, petal_length=1.5, petal_width=0.1, species=u'setosa')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable('mytable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   species|\n",
      "+----------+\n",
      "| virginica|\n",
      "|versicolor|\n",
      "|    setosa|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_classes = sqlContext.sql(\"select distinct species from mytable\")\n",
    "distinct_classes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
